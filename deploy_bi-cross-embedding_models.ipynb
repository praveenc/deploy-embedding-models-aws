{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce6238b-ceae-4f52-acf6-db32ff0c36f1",
   "metadata": {},
   "source": [
    "# Deploy Text Embedding Models to Amazon SageMaker\n",
    "\n",
    "In this notebook, we demonstrate, how we can package both a bi-encoder model for embedding and a cross-encoder model for re-ranking to a single model archive (`model.tar.gz`) and deploy to Amazon SageMaker real-time endpoint with a custom inference script.\n",
    "\n",
    "\n",
    "## Models\n",
    "\n",
    "- Bi-Encoder model for embeddings\n",
    "  - [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- Cross-encoder model for re-ranking\n",
    "  - [sentence-transformers/ms-marco-MiniLM-L-12-v2](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2)\n",
    "\n",
    "## Inference script to handle both embedding and re-ranking\n",
    "\n",
    "Refer to [./models/bi-cross-encoder-minilm/code/inference.py](./models/bi-cross-encoder/code/inference.py) for implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99786908-b4c9-4892-8941-deb01fdf0a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U sagemaker rich watermark --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb393f-c374-41f4-9902-61ffc66db768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from rich import print\n",
    "from sagemaker import get_execution_role, image_uris, model_uris, script_uris\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader, s3_path_join\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1e588-e861-499f-bb6b-6ca3b1d20721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket_name = session.default_bucket()\n",
    "# role = get_execution_role()\n",
    "role = \"arn:aws:iam::726793866085:role/service-role/AmazonSageMaker-ExecutionRole-20220313T104021\"\n",
    "region = session.boto_region_name\n",
    "# Define sagemaker client object to invoke Sagemaker services\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "model_base_name = \"bi-cross-encoder\"\n",
    "model_folder = Path(f\"./models/{model_base_name}\").absolute().resolve()\n",
    "model_archive_path = model_folder.joinpath(\"model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c74c09-fd58-4560-ade0-66020524b902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84138e8b-a245-4174-ba24-1dff210b14e0",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "\n",
    "- Compress model artifacts to `model.tar.gz`\n",
    "- Upload model to S3\n",
    "- Create Model object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bfd02-f6a2-4af2-9c2c-c4a709bdd601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change to model dir and run tar command\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "print(str(model_folder))\n",
    "if not os.path.exists(str(model_archive_path)):\n",
    "    os.chdir(str(model_folder))\n",
    "    command = \"tar -cf model.tar.gz --use-compress-program=pigz **/*.*\"\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "    os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb47c6-c274-4a5c-a362-41fec532fda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_archive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb4872-ba59-47b4-b0df-ffb0ffa7e480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload model artifact to S3\n",
    "suffix = f\"/models/txt-embedding-models/{model_base_name}\"\n",
    "upload_path_s3 = s3_path_join(f\"s3://{bucket_name}\", suffix)\n",
    "print(f\"Uploading the model to {upload_path_s3}\")\n",
    "model_data_url = S3Uploader.upload(\n",
    "    local_path=str(model_archive_path),\n",
    "    desired_s3_uri=upload_path_s3,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "print(f\"Model Data URL: {model_data_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762685e3-d007-4882-bcfd-55779bf4dec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suffix = f\"{str(uuid4())[:5]}-{datetime.now().strftime('%d%b%Y')}\"\n",
    "model_name = f\"{model_base_name}-{suffix}\"\n",
    "instance_type = \"ml.c5.2xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280083f1-422c-4083-a35e-afa453bdf28f",
   "metadata": {},
   "source": [
    "https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1b1bd-8cc3-4d6b-9f96-54c0f89ec609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Creating model: {model_name}\")\n",
    "txt_embed_model = HuggingFaceModel(\n",
    "    model_data=model_data_url,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    transformers_version=\"4.26.0\",\n",
    "    pytorch_version=\"1.13.1\",\n",
    "    sagemaker_session=session,\n",
    "    py_version=\"py39\",\n",
    "    name=model_name,\n",
    "    env={\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"10\"},\n",
    ")\n",
    "\n",
    "txt_embed_model.create(instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd8e3f-f2d7-4f40-958b-27ca95684e96",
   "metadata": {},
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236d8e9-2d27-40ac-ba03-97ee6f874b3b",
   "metadata": {},
   "source": [
    "#### Deploy to Serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e4d70-3401-44b2-a646-f8e8b723dcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Serverless endpoint\n",
    "\n",
    "endpoint_name = model_name\n",
    "endpoint_config_name = f\"{model_name}-epc\"\n",
    "# Memory In GiB\n",
    "memory = 2048\n",
    "max_concurrency = 10\n",
    "\n",
    "# Create endpoint config\n",
    "epc_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ServerlessConfig\": {\n",
    "                \"MemorySizeInMB\": memory,\n",
    "                \"MaxConcurrency\": max_concurrency,\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "status_code = epc_response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "epc_arn = epc_response[\"EndpointConfigArn\"]\n",
    "\n",
    "if status_code == 200:\n",
    "    print(f\"EPC : {endpoint_config_name} created\")\n",
    "    print(f\"Creating endpoint: {endpoint_name}\")\n",
    "    ep_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "    status_code = ep_response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "    print(f\"Endpoint: {endpoint_name}; Status Code: {status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08258356-ee18-44e1-981f-17a5ca8626a2",
   "metadata": {},
   "source": [
    "### Wait for endpoint to be `InService` state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f28f-779b-4636-86a5-177c6c625904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "print(f\"Endpoint [b]{endpoint_name}[/b] Status: [i]{status}[/i]\")\n",
    "\n",
    "# Get the waiter object\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "# Apply the waiter on the endpoint\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "# Get endpoint status using describe endpoint\n",
    "status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "print(f\"Endpoint [b]{endpoint_name}[/b] Status: [i]{status}[/i]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15389224-1675-4525-94af-f7db11607b64",
   "metadata": {},
   "source": [
    "#### Deploy to Real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d5503-4e56-4a93-8fa0-821323349151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# endpoint_name = model_name\n",
    "\n",
    "# predictor = txt_embed_model.deploy(\n",
    "#     instance_type=instance_type,\n",
    "#     initial_instance_count=instance_count,\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     serializer=JSONSerializer(),\n",
    "#     deserializer=JSONDeserializer(),\n",
    "#     wait=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028b422-8ce0-460f-bc4b-081909d294e1",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b184736-fe51-4d8b-b095-e8d5d8e189aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# input_data = {\n",
    "#     \"kind\": \"embeddings\",\n",
    "#     \"sentence\": \"I love Berlin\",\n",
    "# }\n",
    "\n",
    "input_data = {\n",
    "    \"kind\": \"cross-encoder\",\n",
    "    \"sentence\": \"I love Berlin\",\n",
    "    \"candidates\": [\"I love Paris\", \"I love Stuttgart\"],\n",
    "}\n",
    "\n",
    "\n",
    "embeddings = predictor.predict(input_data)\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c0fb5-96db-4b47-9dd5-66bfd9c822d6",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0dedf-fbbc-48a1-ae91-c64cdf59a588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
